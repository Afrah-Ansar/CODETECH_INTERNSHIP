{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOpeO8Cpz91HtxdRNMtpN0W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lntmt723kvsb","executionInfo":{"status":"ok","timestamp":1752154995436,"user_tz":-330,"elapsed":2243,"user":{"displayName":"afrah","userId":"17490696053396075571"}},"outputId":"0aa4b318-3e3e-46cb-d4c5-1534d80d47c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Libraries imported successfully!\n","Setting up comprehensive ETL pipeline...\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.impute import SimpleImputer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","print(\"Libraries imported successfully!\")\n","print(\"Setting up comprehensive ETL pipeline...\")"]},{"cell_type":"code","source":["# Create sample dataset for demonstration\n","np.random.seed(42)\n","\n","# Generate synthetic data\n","n_samples = 1000\n","data = {\n","    'age': np.random.randint(18, 80, n_samples),\n","    'income': np.random.normal(50000, 15000, n_samples),\n","    'education': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], n_samples),\n","    'experience': np.random.randint(0, 40, n_samples),\n","    'city': np.random.choice(['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'], n_samples),\n","    'score': np.random.normal(75, 10, n_samples),\n","    'target': np.random.choice([0, 1], n_samples, p=[0.6, 0.4])\n","}\n","\n","# Introduce some missing values\n","missing_indices = np.random.choice(n_samples, size=int(0.1 * n_samples), replace=False)\n","for idx in missing_indices[:50]:\n","    data['income'][idx] = np.nan\n","for idx in missing_indices[50:]:\n","    data['education'][idx] = None\n","\n","# Create DataFrame\n","df = pd.DataFrame(data)\n","print(\"Sample dataset created with shape:\", df.shape)\n","print(\"\\\n","Dataset info:\")\n","print(df.info())\n","print(\"\\\n","First 5 rows:\")\n","print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GBi7QZyDk_nl","executionInfo":{"status":"ok","timestamp":1752155079225,"user_tz":-330,"elapsed":109,"user":{"displayName":"afrah","userId":"17490696053396075571"}},"outputId":"4656ad23-4bfc-4401-955f-e14ba83c80d0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample dataset created with shape: (1000, 7)\n","Dataset info:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1000 entries, 0 to 999\n","Data columns (total 7 columns):\n"," #   Column      Non-Null Count  Dtype  \n","---  ------      --------------  -----  \n"," 0   age         1000 non-null   int64  \n"," 1   income      950 non-null    float64\n"," 2   education   1000 non-null   object \n"," 3   experience  1000 non-null   int64  \n"," 4   city        1000 non-null   object \n"," 5   score       1000 non-null   float64\n"," 6   target      1000 non-null   int64  \n","dtypes: float64(2), int64(3), object(2)\n","memory usage: 54.8+ KB\n","None\n","First 5 rows:\n","   age        income education  experience         city      score  target\n","0   56  70585.666948  Bachelor          21  Los Angeles  88.466697       0\n","1   69  39833.208605  Bachelor          24     New York  70.256546       0\n","2   46  67302.978080      None          17      Phoenix  75.734345       1\n","3   32  44374.840574       PhD          16      Houston  71.636213       0\n","4   60  39587.810697       PhD          11     New York  87.823635       1\n"]}]},{"cell_type":"code","source":["# ETL Pipeline Class Definition\n","class DataPipeline:\n","    def __init__(self):\n","        self.numerical_features = []\n","        self.categorical_features = []\n","        self.target_column = None\n","        self.preprocessor = None\n","        self.model = None\n","        self.is_fitted = False\n","\n","    def extract_data(self, data_source, **kwargs):\n","        \"\"\"\n","        Extract data from various sources\n","        \"\"\"\n","        if isinstance(data_source, str):\n","            if data_source.endswith('.csv'):\n","                df = pd.read_csv(data_source, **kwargs)\n","            elif data_source.endswith('.xlsx') or data_source.endswith('.xls'):\n","                df = pd.read_excel(data_source, **kwargs)\n","            elif data_source.endswith('.json'):\n","                df = pd.read_json(data_source, **kwargs)\n","            else:\n","                raise ValueError(\"Unsupported file format\")\n","        elif isinstance(data_source, pd.DataFrame):\n","            df = data_source.copy()\n","        else:\n","            raise ValueError(\"Data source must be a file path or pandas DataFrame\")\n","\n","        print(\"Data extracted successfully!\")\n","        print(\"Shape:\", df.shape)\n","        return df\n","\n","    def analyze_data(self, df):\n","        \"\"\"\n","        Analyze data structure and quality\n","        \"\"\"\n","        print(\"=== DATA ANALYSIS ===\")\n","        print(\"Dataset shape:\", df.shape)\n","        print(\"\\\n","Column types:\")\n","        print(df.dtypes)\n","        print(\"\\\n","Missing values:\")\n","        print(df.isnull().sum())\n","        print(\"\\\n","Basic statistics:\")\n","        print(df.describe())\n","\n","        return {\n","            'shape': df.shape,\n","            'dtypes': df.dtypes,\n","            'missing_values': df.isnull().sum(),\n","            'statistics': df.describe()\n","        }\n","\n","# Initialize pipeline\n","pipeline = DataPipeline()\n","print(\"DataPipeline class created successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cQq8MIvvlNsj","executionInfo":{"status":"ok","timestamp":1752155121585,"user_tz":-330,"elapsed":18,"user":{"displayName":"afrah","userId":"17490696053396075571"}},"outputId":"e8503617-dca0-4b45-9b24-0db831ee999a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["DataPipeline class created successfully!\n"]}]},{"cell_type":"code","source":["# Continue ETL Pipeline Class - Transform methods\n","class DataPipeline(DataPipeline):\n","\n","    def transform_data(self, df, target_column=None, numerical_features=None, categorical_features=None):\n","        \"\"\"\n","        Transform data with preprocessing steps\n","        \"\"\"\n","        self.target_column = target_column\n","\n","        # Auto-detect feature types if not provided\n","        if numerical_features is None:\n","            self.numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n","            if target_column and target_column in self.numerical_features:\n","                self.numerical_features.remove(target_column)\n","        else:\n","            self.numerical_features = numerical_features\n","\n","        if categorical_features is None:\n","            self.categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n","            if target_column and target_column in self.categorical_features:\n","                self.categorical_features.remove(target_column)\n","        else:\n","            self.categorical_features = categorical_features\n","\n","        print(\"=== DATA TRANSFORMATION ===\")\n","        print(\"Numerical features:\", self.numerical_features)\n","        print(\"Categorical features:\", self.categorical_features)\n","\n","        # Create preprocessing pipelines\n","        numerical_transformer = Pipeline(steps=[\n","            ('imputer', SimpleImputer(strategy='median')),\n","            ('scaler', StandardScaler())\n","        ])\n","\n","        categorical_transformer = Pipeline(steps=[\n","            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n","            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n","        ])\n","\n","        # Combine preprocessing steps\n","        self.preprocessor = ColumnTransformer(\n","            transformers=[\n","                ('num', numerical_transformer, self.numerical_features),\n","                ('cat', categorical_transformer, self.categorical_features)\n","            ]\n","        )\n","\n","        # Separate features and target\n","        if target_column:\n","            X = df.drop(columns=[target_column])\n","            y = df[target_column]\n","\n","            # Fit and transform features\n","            X_transformed = self.preprocessor.fit_transform(X)\n","\n","            # Get feature names after transformation\n","            num_feature_names = self.numerical_features\n","            cat_feature_names = self.preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(self.categorical_features)\n","            all_feature_names = list(num_feature_names) + list(cat_feature_names)\n","\n","            # Create transformed DataFrame\n","            X_transformed_df = pd.DataFrame(X_transformed, columns=all_feature_names, index=df.index)\n","\n","            print(\"Transformation completed!\")\n","            print(\"Original features:\", len(df.columns) - 1)\n","            print(\"Transformed features:\", X_transformed_df.shape[1])\n","\n","            return X_transformed_df, y\n","        else:\n","            X_transformed = self.preprocessor.fit_transform(df)\n","            num_feature_names = self.numerical_features\n","            cat_feature_names = self.preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(self.categorical_features)\n","            all_feature_names = list(num_feature_names) + list(cat_feature_names)\n","\n","            X_transformed_df = pd.DataFrame(X_transformed, columns=all_feature_names, index=df.index)\n","\n","            print(\"Transformation completed!\")\n","            print(\"Original features:\", len(df.columns))\n","            print(\"Transformed features:\", X_transformed_df.shape[1])\n","\n","            return X_transformed_df\n","\n","    def run_full_pipeline(self, data_source, target_column=None, numerical_features=None, categorical_features=None, **kwargs):\n","        \"\"\"\n","        Runs the complete ETL pipeline: Extract, Analyze, Transform\n","        \"\"\"\n","        df = self.extract_data(data_source, **kwargs)\n","        self.analyze_data(df)\n","        return self.transform_data(df, target_column, numerical_features, categorical_features)\n","\n","\n","# Update pipeline instance\n","pipeline = DataPipeline()\n","print(\"Enhanced DataPipeline with transform methods created!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B8lAlJBqlZ0p","executionInfo":{"status":"ok","timestamp":1752155263991,"user_tz":-330,"elapsed":184,"user":{"displayName":"afrah","userId":"17490696053396075571"}},"outputId":"1f0dee40-00a7-4e4b-9fb6-4d9861df6552"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Enhanced DataPipeline with transform methods created!\n"]}]},{"cell_type":"code","source":["# Demonstrate the ETL pipeline with our sample data\n","print(\"=== DEMONSTRATING ETL PIPELINE ===\")\n","\n","# Run the complete pipeline\n","pipeline_results = pipeline.run_full_pipeline(\n","    data_source=df,\n","    target_column='target'\n",")\n","\n","print(\"\\nPipeline execution completed!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VMSVrmYElkKm","executionInfo":{"status":"ok","timestamp":1752155264647,"user_tz":-330,"elapsed":52,"user":{"displayName":"afrah","userId":"17490696053396075571"}},"outputId":"3ae570ac-ec3d-48bf-ce49-f492192c38b3"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["=== DEMONSTRATING ETL PIPELINE ===\n","Data extracted successfully!\n","Shape: (1000, 7)\n","=== DATA ANALYSIS ===\n","Dataset shape: (1000, 7)\n","Column types:\n","age             int64\n","income        float64\n","education      object\n","experience      int64\n","city           object\n","score         float64\n","target          int64\n","dtype: object\n","Missing values:\n","age            0\n","income        50\n","education      0\n","experience     0\n","city           0\n","score          0\n","target         0\n","dtype: int64\n","Basic statistics:\n","               age        income   experience        score       target\n","count  1000.000000    950.000000  1000.000000  1000.000000  1000.000000\n","mean     49.857000  50613.785845    19.664000    75.099916     0.393000\n","std      18.114267  15822.158955    11.479586     9.853115     0.488661\n","min      18.000000  -3523.079490     0.000000    46.001062     0.000000\n","25%      35.000000  40571.729158    10.000000    68.421346     0.000000\n","50%      50.000000  51194.540487    20.000000    74.865722     0.000000\n","75%      66.000000  61263.831081    29.000000    82.043410     1.000000\n","max      79.000000  97616.632057    39.000000   102.659796     1.000000\n","=== DATA TRANSFORMATION ===\n","Numerical features: ['age', 'income', 'experience', 'score']\n","Categorical features: ['education', 'city']\n","Transformation completed!\n","Original features: 6\n","Transformed features: 14\n","\n","Pipeline execution completed!\n"]}]}]}